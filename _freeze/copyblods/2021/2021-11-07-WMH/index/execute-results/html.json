{
  "hash": "d70de840d04db2c21fe833c09455b516",
  "result": {
    "markdown": "---\ntitle: Toolbox for WMH\nauthor: 桑峰\ndate: 2021-11-07\nslug: blog\noutput: html_document\ncategories:\n  - Toolbox\ntags:\n  - WMH\n  - LST\n  - BIANCA\n  - SLS\n  - UBO\n  - W2MHS\n---\n\n\n## 介绍\n\n白质高信号（white matter hyperintensity, WMH）是一种因脑白质病变导致的、在T2 Flari像上表现为高灰质值的现象。在相关研究中，确定白质高信号区域是一个基本的问题。一般认为，由专业的影像科医生或受过培训的人员手动分割的结果是金标准。然而，手动分割费时费力。因而，研究者提出了许多自动半自动的分割工具。本文将对几种常用的白质高信号自动分割工具的用法进行简单介绍。\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](./img/fig_01.png){width=404}\n:::\n:::\n\n\n## LST\n\nLST (https://www.applied-statistics.de/lst.html) 是基于SPM的白质高信号分割工具，它包含两个分割算法：LPA和LGA。其中，LPA不需要T1数据，而LGA需要T1和Flari数据。\n\n代码入下：\n\n### LPA\n\n尽管LPA在分割WMH的时候不需要T1数据，然而在输入里面还是可以将T1数据输入，用来作为配准的参考图像。\n\n```matlab\n% WMH segment by LPA in LST.\nclose all; clear; clc;\n\n% Set SPM12 into Path.\nSPM_PATH = '~/Tools/spm12';\naddpath(SPM_PATH);\n\n% Set root path.\nROOT = 'Work';\n\nsubs = dir(ROOT);\nsubs = subs(3:end);\nfor i = 1:numel(subs)\n    % for single subject.\n    disp(subs(i).name);\n    sub_path = fullfile(ROOT, subs(i).name);\n    \n    t1_path = fullfile(sub_path, 't1.nii');\n    if ~exist(t1_path, 'file')\n        % gunzip the .gz file.\n        gunzip(fullfile(sub_path, 't1.nii.gz'));\n    end\n    flair_path = fullfile(sub_path, 'flair.nii');\n    if ~exist(flair_path, 'file')\n        gunzip(fullfile(sub_path, 'flair.nii.gz'));\n    end\n    \n    pause(10);\n    \n    spm_jobman('initcfg');\n    matlabbatch{1}.spm.tools.LST.lpa.data_F2 = {strcat(flair_path, ',1')};\n    matlabbatch{1}.spm.tools.LST.lpa.data_coreg = {strcat(t1_path, ',1')};\n    matlabbatch{1}.spm.tools.LST.lpa.html_report = 1;\n    spm('defaults', 'pet');\n    spm_jobman('run', matlabbatch);\n    clear matlabbatch;\nend\n```\n\n### LGA\n\n```matlab\n% WMH segment by LGA in LST.\nclose all; clear; clc;\n\n% Set SPM12 into Path.\nSPM_PATH = '/home/babri3/Tools/spm12';\naddpath(SPM_PATH)\n\n% Set root path.\nROOT = 'Work';\n\n\nsubs = dir(ROOT);\nsubs = subs(3:end);\nfor i = 1:numel(subs)\n    % for single subject.\n    disp(subs(i).name);\n    sub_path = fullfile(ROOT, subs(i).name);\n    \n    t1_path = fullfile(sub_path, 't1.nii');\n    if ~exist(t1_path, 'file')\n        % gunzip the .gz \n        gunzip(fullfile(sub_path, 't1.nii.gz'));\n    end\n    flair_path = fullfile(sub_path, 'flair.nii');\n    if ~exist(flair_path, 'file')\n        gunzip(fullfile(sub_path, 'flair.nii.gz'));\n    end\n    pause(10);\n    disp(t1_path);\n    disp(flair_path);\n    spm_jobman('initcfg');\n   %-----------------------------------------------------------------------\n    % Job saved on 29-Sep-2020 18:30:58 by cfg_util (rev $Rev: 6942 $)\n    % spm SPM - SPM12 (7219)\n    % cfg_basicio BasicIO - Unknown\n    %-----------------------------------------------------------------------\n    matlabbatch{1}.spm.tools.LST.lga.data_T1 = {strcat(t1_path, ',1')};\n    matlabbatch{1}.spm.tools.LST.lga.data_F2 = {strcat(flair_path, ',1')};\n    matlabbatch{1}.spm.tools.LST.lga.opts_lga.initial = 0.3;\n    matlabbatch{1}.spm.tools.LST.lga.opts_lga.mrf = 1;\n    matlabbatch{1}.spm.tools.LST.lga.opts_lga.maxiter = 50;\n    matlabbatch{1}.spm.tools.LST.lga.html_report = 1;\n    spm('defaults','pet');\n    spm_jobman('run', matlabbatch);\n    clear matlabbatch;\nend\n```\n\n## BIANCA\n\nBIANCA (https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/BIANCA) 是一种基于监督学习的WMH分割工具，是FSL的一个子模块。在使用它之前，需要先得到一部分被试的分割结果作为训练数据。可用其他的自动化分割方法的结果作为训练数据。\n\nBIANCA需要一个master文件用于指定训练数据的路径。生成master文件的代码如下：\n\n```python\nsrc = 'Work-BIANAC'\nres = ''\n\nfor i in os.listdir(src):\n    sub_path = os.path.join(src, i)\n    \n    res += '{}\\t{}\\t{}\\t{}\\n'.format(\n        os.path.join(sub_path, 't1_brain.nii.gz'),\n        os.path.join(sub_path, 'flair_to_t1.nii.gz'),\n        os.path.join(sub_path, 't1_brain_to_mni.mat'),\n        os.path.join(sub_path, 'lesion_lpa.nii')\n    )\n\nwith open('masterfile_lpa.txt', 'w') as f:\n    f.writelines(res)\n    logging.info('Finished.')\n```\n\n另外，BIANCA需要标准空间下的脑组织图像（对T1图像进行bet和配准操作），代码如下：\n\n```python\nimport os\nimport shutil\nfrom nipype.interfaces import fsl\nimport logging\n\nsrc = 'Work-BIANAC'\nfor i in os.listdir(src):\n  logging.info(f'{i}...')\n  sub_path = os.path.join(src, i)\n  \n  if not os.path.exists(os.path.join(sub_path, 'lesion_lga.nii')):\n    shutil.copy(os.path.join('Work-LST', i, 'ples_lga_0.3_rmflair.nii'),\n                os.path.join(sub_path, 'lesion_lga.nii'))\n    shutil.copy(os.path.join('Work-LST', i, 'ples_lpa_mrflair.nii'),\n                os.path.join(sub_path, 'lesion_lpa.nii'))\n    \n  \n  # flair to t1\n  flt_flair_to_t1 = fsl.FLIRT(bins=256, cost_func='corratio')\n  flt_flair_to_t1.inputs.in_file = os.path.join(sub_path, 'flair.nii.gz')\n  flt_flair_to_t1.inputs.reference = os.path.join(sub_path, 't1.nii.gz')\n  flt_flair_to_t1.inputs.output_type = 'NIFTI_GZ'\n  flt_flair_to_t1.inputs.out_file = os.path.join(sub_path, 'flair_to_t1.nii.gz')\n  flt_flair_to_t1.inputs.out_matrix_file = os.path.join(sub_path, 'flair_to_t1.mat')\n  logging.info(flt_flair_to_t1.cmdline)\n  res_flt_flair_to_t1 = flt_flair_to_t1.run()\n  logging.info('Finish...')\n  \n  # betting t1\n  btr_t1 = fsl.BET()\n  btr_t1.inputs.in_file = os.path.join(sub_path, 't1.nii.gz')\n  btr_t1.inputs.frac = 0.5\n  btr_t1.inputs.out_file = os.path.join(sub_path, 't1_brain.nii.gz')\n  btr_t1.inputs.output_type = 'NIFTI_GZ'\n  btr_t1.inputs.mask = True\n  btr_t1.inputs.robust = True\n  logging.info(btr_t1.cmdline)\n  res_btr_t1 = btr_t1.run()\n  logging.info('Finish...')\n\n  \n  # t1 to mni\n  flt_t1_to_mni = fsl.FLIRT(bins=256, cost_func='corratio')\n  flt_t1_to_mni.inputs.in_file = os.path.join(sub_path, 't1_brain.nii.gz')\n  flt_t1_to_mni.inputs.reference = '/usr/local/fsl/data/standard/MNI152_T1_2mm_brain.nii.gz'\n  flt_t1_to_mni.inputs.output_type = 'NIFTI_GZ'\n  flt_t1_to_mni.inputs.out_file = os.path.join(sub_path, 't1_brain_to_mni.nii.gz')\n  flt_t1_to_mni.inputs.out_matrix_file = os.path.join(sub_path, 't1_brain_to_mni.mat')\n  logging.info(flt_t1_to_mni.cmdline)\n  res_flt_t1_to_mni = flt_t1_to_mni.run()\n  logging.info('Finish...')\n```\n\n运行BIANCA，代码如下：\n\n```python\nimport os\nimport logging\n\nsrc = 'Work-BIANCA'\nsubs = os.listdir(src)\nfor i in range(len(subs)):\n  sub_path = os.path.join(src, subs[i])\n  cmdline = 'bianca '\\\n      + '--singlefile=masterfile_lga.txt '\\\n      + '--labelfeaturenum=4 '\\\n      + '--brainmaskfeaturenum=1 '\\\n      + '--querysubjectnum=#1 '\\\n      + '--trainingnums=1,2,3,4,5,6,7,8,9,10 '\\\n      + '--featuresubset=1,2 '\\\n      + '--matfeaturenum=3 '\\\n      + '--trainingpts=2000 '\\\n      + '--nonlespts=10000 '\\\n      + '--selectpts=noborder '\\\n      + '-o #2 -v'\n  cmdline = cmdline.replace('#1', str(i+1))\n  cmdline = cmdline.replace('#2', os.path.join(sub_path, 'bianca_output_lga'))\n  logging.info(cmdline)\n  os.system(cmdline)\n  logging.info('Finished lga.')\n  \n  cmdline = 'bianca '\\\n      + '--singlefile=masterfile_lpa.txt '\\\n      + '--labelfeaturenum=4 '\\\n      + '--brainmaskfeaturenum=1 '\\\n      + '--querysubjectnum=#1 '\\\n      + '--trainingnums=1,2,3,4,5,6,7,8,9,10 '\\\n      + '--featuresubset=1,2 '\\\n      + '--matfeaturenum=3 '\\\n      + '--trainingpts=2000 '\\\n      + '--nonlespts=10000 '\\\n      + '--selectpts=noborder '\\\n      + '-o #2 -v'\n  cmdline = cmdline.replace('#1', str(i+1))\n  cmdline = cmdline.replace('#2', os.path.join(sub_path, 'bianca_output_lpa'))\n  logging.info(cmdline)\n  os.system(cmdline)\n  logging.info('Finished lga.')\n```\n\n## SLS\n\nSLS (http://atc.udg.edu/salem/slsToolbox/docs.html) 也是基于SPM的一种WMH分割工具包，需要将其安装文件夹放置于SPM的toolbox文件夹下。运行代码如下：\n\n```matlab\n% WMH segment by SLS.\nclear all; clc; close all;\n\n% Set SPM12 into Path.\nSPM_PATH = '~/Tools/spm8';\naddpath(SPM_PATH);\nSLS_PATH = fullfile(SPM_PATH, 'toolbox', 'SLSToolBox');\naddpath(genpath(SLS_PATH));\n\n% Set root path.\nROOT = 'Work-SLS';\n\nsubs = dir(ROOT);\nsubs = subs(3:end);\nfor i = 1:numel(subs)\n    % for single subject.\n    disp(subs(i).name);\n    sub_path = fullfile(ROOT, subs(i).name);\n    \n    t1_path = fullfile(sub_path, 't1.nii');\n    flair_path = fullfile(sub_path, 'flair.nii');\n\n    spm_jobman('initcfg');\n    matlabbatch{1}.spm.tools.SLS.lesionSegment.data_T1 = {strcat(t1_path, ',1')};\n    matlabbatch{1}.spm.tools.SLS.lesionSegment.data_FLAIR = {strcat(flair_path, ',1')};\n    matlabbatch{1}.spm.tools.SLS.lesionSegment.params.stIter.alpha = 2.5;\n    matlabbatch{1}.spm.tools.SLS.lesionSegment.params.stIter.omegaT = 0.6;\n    matlabbatch{1}.spm.tools.SLS.lesionSegment.params.stIter.omegaN = 0.55;\n    matlabbatch{1}.spm.tools.SLS.lesionSegment.params.stIter.lesionSize = 30;\n    matlabbatch{1}.spm.tools.SLS.lesionSegment.params.ndIter.alpha2 = 2;\n    matlabbatch{1}.spm.tools.SLS.lesionSegment.params.ndIter.omegaT2 = 0.75;\n    matlabbatch{1}.spm.tools.SLS.lesionSegment.params.ndIter.omegaN2 = 0.7;\n    matlabbatch{1}.spm.tools.SLS.lesionSegment.params.ndIter.lesionSize2 = 20;\n    matlabbatch{1}.spm.tools.SLS.lesionSegment.exclusion.ventricles = 0;\n    matlabbatch{1}.spm.tools.SLS.lesionSegment.outputs.lesionMaskst = 0;\n    matlabbatch{1}.spm.tools.SLS.lesionSegment.outputs.lesionMasknd = 0;\n    matlabbatch{1}.spm.tools.SLS.lesionSegment.outputs.thrst = 0;\n    matlabbatch{1}.spm.tools.SLS.lesionSegment.outputs.thrnd = 0;\n    matlabbatch{1}.spm.tools.SLS.lesionSegment.outputs.cleanup = 0;\n\n    spm('defaults', 'pet');\n    spm_jobman('run', matlabbatch);\n    clear matlabbatch;\nend\n```\n\n## W2MHS\n\nW2MHS (https://www.nitrc.org/projects/w2mhs/) 是基于MATLAB的一种WMH分割工具，运行前需要将安装文件夹添加进MATLAB的搜索路径中。其运行脚本如下：\n\n```matlab\n% WMH segment by W2MHS.\n\nclear all; clc; close all;\noutput_path = {'Work-W2MHS/Output'};\noutput_name = {'W2MHS'};\noutput_ids = {'sub-1', 'sub-1'; 'sub-2', 'sub-2'; 'sub-3', 'sub-3'; 'sub-4', 'sub-4'; 'sub-5', 'sub-5';...\n    'sub-6', 'sub-6'; 'sub-7', 'sub-7'; 'sub-8', 'sub-8'; 'sub-9', 'sub-9'; 'sub-10', 'sub-10'};\ninput_images = {'Work-W2MHS/T1/sub-01_t1.nii', 'Work-W2MHS/FLAIR/sub-01_flair.nii';...\n    'Work-W2MHS/T1/sub-02_t1.nii', 'Work-W2MHS/FLAIR/sub-02_flair.nii';...\n    'Work-W2MHS/T1/sub-03_t1.nii', 'Work-W2MHS/FLAIR/sub-03_flair.nii';...\n    'Work-W2MHS/T1/sub-04_t1.nii', 'Work-W2MHS/FLAIR/sub-04_flair.nii';...\n    'Work-W2MHS/T1/sub-05_t1.nii', 'Work-W2MHS/FLAIR/sub-05_flair.nii';...\n    'Work-W2MHS/T1/sub-06_t1.nii', 'Work-W2MHS/FLAIR/sub-06_flair.nii';...\n    'Work-W2MHS/T1/sub-07_t1.nii', 'Work-W2MHS/FLAIR/sub-07_flair.nii';...\n    'Work-W2MHS/T1/sub-08_t1.nii', 'Work-W2MHS/FLAIR/sub-08_flair.nii';...\n    'Work-W2MHS/T1/sub-09_t1.nii', 'Work-W2MHS/FLAIR/sub-09_flair.nii';...\n    'Work-W2MHS/T1/sub-10_t1.nii', 'Work-W2MHS/FLAIR/sub-10_flair.nii'};\ninput_meth = {'rf_regress'};\nw2mhstoolbox_path = './Work-W2MHS/W2MHS';\nspmtoolbox_path = '/home/babri3/Tools/spm12';\ndo_train = 'no';\ndo_preproc = 'no'; \ndo_quantify = 'yes';\nparam(.6, 2.5, 'yes');\nWhyD_setup(output_name, output_path, input_images, output_ids, w2mhstoolbox_path,...\n    spmtoolbox_path, do_train, do_preproc, do_quantify);\n```\n\n## UBO\n\n另外，还有一种基于MATLAB和SPM的分割工具包UBO，它的使用手册：https://cheba.unsw.edu.au/sites/cheba2/files/_local_upload/pdf/groups/neuroimaging-group-pipeline-quick-start-manual.pdf.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](./img/fig_02.png){width=846}\n:::\n:::\n\n\n## 部分分割结果\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](./img/fig_03.png){width=686}\n:::\n:::\n\n\n## 相关链接\n\nLST: https://www.applied-statistics.de/lst.html\n\nBIANCA: https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/BIANCA\n\nSLS: http://atc.udg.edu/salem/slsToolbox/docs.html\n\nW2MHS: https://www.nitrc.org/projects/w2mhs/\n\nUBO: https://cheba.unsw.edu.au/research-groups/neuroimaging/pipeline",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}